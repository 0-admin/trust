During the trench warfare of World War I, peace broke out.

It was Christmas 1914. Despite specific orders not to hang out & chill with the enemy, British and German soldiers left their trenches, crossed No Man's Land, and gathered together to bury their dead, exchange gifts, and sing. This wasn't unique. Even long *before* Christmas, soldiers in trenches had already created an unspoken system of "live and let live" – a small peace in a Great War.

...

Meanwhile, the West has now been at peace for decades, and wow, we hate each other more than ever. Since 1970, people have lost a lot of trust in their governments, their media, and even *themselves*. So here's our two-part question:

**Why, even in the best of times, do friends become enemies?    
And why, even in the worst of times, do enemies become friends?**

It's a complex question, but there's a simple idea from game theory can shed a lot of light on this! So, to understand our epidemic of distrust...

...let's play a game.

---

**THE GAME OF TRUST:** (Note: also known as "The Prisoner's Dilemma")

There's a machine. If one player puts a coin in the machine, the *other* player gets three coins. A player can either choose to COOPERATE (put in one coin), or CHEAT (keep their coin).

But there's a problem. Think about it: if the other player CHEATS, what should you do?

---

Fair enough – if the other player won't cooperate, why should you?

Alas, turning the other cheek just gets you slapped on that cheek.

Cooperating while the other person cheats means you lose a coin while they get three. (-1 vs +3) However, both of you cheating means you both neither gain nor lose anything. (0 vs 0) Therefore, you should CHEAT.

But if the other player COOPERATES, what should you do now?

---

Wow, that's mean. And also the correct answer!

Yeah, seems like the right thing to do... but is it the *correct* thing to do?

Because, if you both cooperate, you both lose one coin and gain three (+2 vs +2). But you can do *even better* – if you cheat while they cooperate, *you* can gain three coins at no cost, while they lose a coin. (+3 vs -1) Therefore, you should *still* CHEAT.

So, even though you'd be better off both cooperating (+2 vs +2) than both cheating (0 vs 0), both of you *always* have the incentive to cheat. (Note: In game theory, games without win-wins are called "zero-sum games", and games where win-wins are possible, even if not likely, are called "non-zero-sum games")

(well, so what? >)

---

Now, now – this game may seem contrived, but, like a street map, it's only by getting *rid* of details, can we find our way around a complex topic!

And here, our simple game captures the dilemma of trust:

**we'd be better off if everybody trusted each other, but trust makes you vulnerable to being taken advantage of.**

But what if...

(...we play more than once?)

---

Now, you'll be playing this game against five different characters. With each character, you'll play anywhere between 3 to 10 rounds. (neither of you will know when the last round is, and that's important)

Will they take advantage of you? Will you take advantage of *them*? Let's find out. Choose your first move:

---

Alright, let's try a new character: (#2 of 5)

And yet another character: (#3 of 5)

How about this guy? (#4 of 5)

And finally... (#5 of 5)

---

Pretty good: you scored ____!

Not too bad: you scored ____!

Well, uh, you tried: you scored _____.

(lowest possible score: ///. highest possible score: ///)

Now, who were these strange characters?

COPYCAT: I start with Cooperate, and then, I just copy whatever move you did last time. Meow

ALWAYS CHEAT: i hate you

ALWAYS COOPERATE: I love you! <3

GRUDGER: "Listen y'all – I start Cooperatin', and I'll keep on Cooperatin'... but if you ever Cheat me once, pardner, I AIN'T EVER FORGIVIN' YOU."

DETECTIVE: "First: I analyze you. I start: Cooperate, Cheat, Cooperate, Cooperate. Then: if you retaliated with a Cheat, I switch to playing Copycat. But: if you never fight back, I switch to Always Cheat. My dear Watson: elementary."

now what if these characters...

(...were to play against each other?)

---

It's tournament time! These five characters will now play against each other – 10 paired games, 10 rounds per game.

Place your bets: who do you think will get the highest *total* score?

---

Alright, you placed your bet on _____! Let's see how each pair plays against each other, one by one...

(first pair >)

/////// [+score] - [-score] ///////

how they played: [payoff] [payoff] [payoff] [payoff] [payoff] 

(next pair >)

(and the winner is... >)

---

COPYCAT! (Note: this play-style is also known in game theory as "Tit For Tat")

Congrats, you placed your bet on the right horse.

Sorry, //////.

Now, here's the strange thing: Copycat can _never_ beat another player in the trust game (because it never tries to take advantage of others), it can only ever do _as well as_ the other player. And yet overall, Copycat wins! This, despite being simpler than Detective, nicer than Always Cheat, and more forgiving than Grudger. It almost seems to imply that the Golden Rule is not just a moral truth, but a *mathematical* truth:

*Do unto others as you would have them do unto you.* ~Copycat

And *that's* why "peace" broke out in the trenches of World War I. Each side was playing a deadly game of trust with each other, but because the nature of trench warfare means they have to face the same group of soldiers over and over again, that allowed a Copycat-like strategy – the unspoken law of "live and let live" – to evolve.

(...but does Copycat *always* win?)

---

Let's go one step further. On top of playing repeated *rounds* of the trust game, let's play repeated *tournaments* of the trust game. Here's what will happen:

1. Play a tournament: everyone plays against everyone.

2. Eliminate the bottom 5 players. (if there's a tie, choose between them randomly)

3. Reproduce the top 5 players! (if there's a tie, choose between them randomly)

(Note: This method is called "evolutionary game theory". Of course, in real life, behavior doesn't *have* to spread by people reproducing & dying. The important thing is simply that successful strategies spread, and unsuccessful ones go away. This could just be done by people imitating more successful people. Also important: "evolution" happens from the bottom up, not the top down!)

Here's our starting "population" of players: 15 Always Cooperates. 5 Always Cheats. 5 Copycats. (Let's ignore Detective & Grudger for now) Who do you think will win in the first tournament?

---

Makes sense, Copycat won in the last tournament, maybe they'll win again.

Makes sense, the Always Cooperates *do* vastly outnumber everyone else now, maybe they have the advantage?

Makes sense, Always Cheat has a *lot* of Always Cooperate suckers to take advantage of.

Let's put it to the test:

(1. play tournament)

(2. eliminate bottom 5)

(3. reproduce top 5)

---

Alas, Copycat lost this time! 

Alas, Always Cooperate *still* got preyed upon!

Sadly, you were correct!

Always Cheat won in this "population" of players, and what's worse, because they won, they now make up an even bigger part of the population. Will this continue?

(1. play tournament)

(2. eliminate bottom 5)

(3. reproduce top 5)

---

Yes, yes it continues. But if we keep going...

(1. play tournament)

(2. eliminate bottom 5)

(3. reproduce top 5)

---

...eventually Always Cheat becomes a victim of their own success: they run out of Always Cooperate suckers to exploit, letting Copycat be able to "invade" the majority Always Cheat population – and the meek Copycats inherit the earth. (or, inherit this small simulation, anyway) Which reminds me of my favorite quote:

*"We are not punished for our sins, but by them."* ~Elbert Hubbard

(Note on "invasion": a *single* Copycat can't "invade" an Always Cheat world. You'd need at least a few Copycats who can cooperate with each other, in order to out-compete Cheaters. And nothing can "invade" a Copycat world, although if someone else ties with Copycat, random elimination & reproduction could cause "population drift" towards that someone else.)

Now, will Copycat still win even if we bring back...

(...Detectives & Grudgers?)

---

(play!)

---

Yes, the Golden Rule-abiding Copycats can still win, in the long run, under a wide variety of circumstances! But there's, uh, a problem with this idea.

Look around. The world is *full* of f@%$ers.

So even though fairness can thrive even in the trenches, nastiness can propagate even in peacetime. What gives? Let's now look at what can cause...

(...the evolution of *distrust*)

---

Here's a Copycat world, with just a few Always Cheaters. Normally, these Always Cheaters will be unable to invade, and get punished pretty quickly:

(play simulation)

---

But let's change the rules of the tournament: instead of playing 10 rounds per paired game, you only played 5? Or 3? 2? 1?

(slider)

(play | stop)

...(and voila >)

---

Without *a high number of repeat interactions,* the Cheaters win, and the Copycats die.

And that's why during World War I, "live and let live" kept popping up in the trenches, *but not anywhere else*. It's not because of the people in the trench, but because of *the trench itself:* it forces lots of repeat interactions between the *same* two groups of soldiers, something that doesn't usually happen in war.

This may also be why trust is declining now, in peacetime. In the last few decades, there's been a huge drop in "social capital": people are making fewer friendships across political, racial, and class lines – because people are making fewer friendships, period. And with fewer repeated interactions, the easier it is for distrust to invade our population.

(Note: *Depth* of relationships > *Breadth* of relationships. You get more trust having lots of interactions with a few people, than having few interactions with lots of people. The internet has made us better at breadth, but not depth.)

But wait...

(...it gets worse for Copycat >)

---

Let's have the same thing as before, but this time each pair only plays 5 rounds. That's still enough for Copycat to win, as you can see...

(play)

---

But now, let's see what happens if we just _slightly_ change the rewards & punishments. (Note: in game theory, this is called a "payoff matrix". Payoff = reward/punishment. Matrix = fancy word meaning "a grid of numbers".)

Change the +2 reward to a +1:

So, both players cooperating (+1 vs +1) is _still_ better than both players cheating (0 vs 0). There's still a win-win, and it's better than the lose-lose. But watch what happens now:

(play)

---

Oh no. Cheaters win again.

The exact numbers for the rewards/punishments aren't important, what's important is the *relative amount* between them. That's why trust could evolve in the trenches: the win-win scenario was just nothing happening, but the lose-lose scenario was _dying in a ditch_.

And as for nowadays, I don't know, maybe there's relatively less reward for achieving a win-win. In this age of political polarization, working with "the other side" isn't praised as being a bridge-builder, but being a traitor, a sell-out. (Not to mention: win-lose conflict gets more media attention than win-win cooperation.) Maybe a lack of win-wins is both the cause *and* effect of our growing distrust.

But wait...

(it gets *even worse* for Copycat >)

---

Copycat has a huge weakness. To see this weakness, let's go back to the two-player repeated game.

Let's say you're a Copycat playing against another Copycat. Copycats start off being nice, so that's why your first move is:

(cooperate)

---

Everything's going hunky-dory at first, both of you cooperating, but then...

(cooperate)

---

[Copycat TRIPS]

Oh no! You made a mistake, and accidentally "Cheated" when you meant to Cooperate. Well, the other Copycat won't take that lying down...

(cooperate)

---

The other Copycat retaliates against what they perceived to be a Cheat...

which seems unfair to you, so *you've* got to retaliate...

(cheat)

---

...and so *they've* got to retaliate, so *you've* got to retaliate, and so on, and so on.

[auto-play]

So, when you allow for the possibility of mistakes, Copycat turns into a *disaster*. Like the Hatfields vs the McCoys, it's a permanent cycle of revenge.

But now, let's introduce three more types of players, who might be able to thrive in a bit of randomness...

(meet the new players >)

---

COPYKITTEN: Hi, I'm like Copycat! But I only return a Cheat after you Cheat me twice in a row because, well, the first one might just be an honest mistake! :3

SIMPLETON: "i try start Cooperate. u cooperate = good = i do what i do in last round, even if mistaek. u cheat = bad = i do opposite of what i do in last round, even if mistaek."

LOL SO RANDOM: monkey tacos! robot ninja bacon pirate! i randomly play cheat or cooperate with 50-50 chance coz lol i'm so random

(wow, nice lineup >)

---

Now, let's consider this starting population of players: 13 Always Cooperates, and 3 each of Copycat, Copykitten, Simpleton, and Random.

Each paired game plays for 10 rounds. And in each round, there's a 5% chance a player makes a mistake, and does the opposite of what they intended to.

Place your bets: who do you think will win?

---

You bet on ///////. Alright, let's give it a whirl:

---

And the winner is... SIMPLETON! (congrats, you guessed correct!) (sorry, /////.)

This is because Simpleton (also known as "Pavlov" or "Win-Stay Lose-Shift") is capable of taking advantage of Always Cooperates: if Simpleton mistakenly Cheats an Always Cooperate, because Always Cooperate doesn't Cheat back, Simpleton keeps on Cheating.

(now, let's try a tougher population >)

---

This population is the same as before, but all the Always Cooperates are now Always Cheats. A much less forgiving environment. (Same rules: 10 rounds per paired game, 5% chance of mistake per round)

Place your bets: who do you think will win now?

---

You bet on ///////. Let's see what happens this time...

---

And the winner is... COPYKITTEN! (congrats, you guessed correct!) (sorry, /////.)

This is because Copykitten (also known as "Tit For Two Tats") does much better than Simpleton against Always Cheat. Copykitten, after being cheated twice, will keep returning cheats to Always Cheat. But Simpleton changes moves *every* time it's cheated, so when playing against Always Cheat, it keeps switching between cooperate & cheat. (Note: Copykitten is so nice that it doesn't even wipe out Copycat, it _shares_ the world with them!)

So the good news is, with a little bit of "random noise" (likelihood of mistakes), a _more forgiving, generous version_ of Copycat can win!

(and the bad news is... >)

---

This isn't true for _all_ levels of "random noise". Let's start 5 of each: Always Defect, Copycat, Copykitten, Simpleton, and Random. Who will win at 0% Noise? 10% Noise? 20% Noise? 50% Noise? (it only goes up to 50% because that's *entirely* random: every move is a coin flip between Cheat & Cooperate)

Make your prediction *before* hitting the "play simulation" button! Once you see the result for one level of random noise, hit "reset", and try again with a different level of random noise.

(what just happened? >)

---

Whoof, we have a *very* wide range of results.

At 0% Randomness: Copycat dominates most of the population, but shares with Copykitten & Simpleton. (due to random elimination & reproduction, the population may "drift" towards fully Copycat)

At 10% Randomness: Copycat seems to win at first... but wait, then Copykitten takes over! (and shares a bit with Copycat)

At 20% Randomness: Good loses the battle between good and evil. Always Cheat takes over *everything*.

At 50% Randomness: There *is no difference* between good and evil. Nobody wins, it's an amoral nightmare where nothing means anything to nobody. (Groups growing & shrinking are due entirely to population drift.)

(in other words... >)

---

A little randomness: more forgiveness and cooperation

A lot of randomness: no forgiveness *or* cooperation

Entirely randomness: ¯\\\_(ツ)\_/¯

Remember, "randomness" here just means the probability of making a mistake, or miscommunication. Now, think about how often in mass media or on the internet people take things out of context (intentionally or not) and misinterpret each others' motives and messages – in contrast with face-to-face in-person interactions, where miscommunication is less likely.

That's pure speculation on my part, but maybe that's another reason...

(...why trust is falling these days>)

---

So to wrap up, (finally!) here are the three conditions needed for **the evolution of trust** – and if you're missing *any* of them, you'll get what we're seeing today: **the evolution of distrust.**

**1. REPEATED INTERACTIONS**

When you play with the same people over and over, you can build trust! But if you have few repeated interactions – or none at all – cheaters go unpunished, and trust-building goes unrewarded.

**2. WIN-WIN REWARDS**

On the upside, even if the win-win reward is *smaller* than the temptation to cheat, fairness can still win in the long run! But on the downside, if the win-win reward is *too* small (relatively), cooperation will fall apart.

**3. LOW NOISE**

When there's a chance for miscommunication, it pays to be *more*  forgiving! But this is only true up to a point: if there's *too much* "random noise", then you just can't trust anybody.

And of course, all these interact with each other in complex ways, ways I know *I* don't fully understand! Maybe you can even discover something completely new, by playing with...

(The Sandbox Mode! >)

---

you can change *all the rules* here in the sandbox mode.
once when you're done playing, (click here to move on >)

---

The world right now seems like a scary place. A bitter, distrustful, conflict-filled place. Deep inside these trenches, in this No Man's Land – how can you, a single person, change all this?

(and the answer is... >)

---

...you can't.

...

...

(however... >)

---

There *is* one person you can always change: you.

*You* can create more **repeated interactions** with individual people outside your tribe...

find **win-wins**, when the world just seems to want a win-lose fight...

and strive for **low noise** not just by communicating clearly, but also forgiving others' mistakes, and humbly owning up to your own.

(and then... >)

---

Through your low-noise, win-win, repeated interactions with people, you may convince a few others to do the same...

(and then... >)

---

Your small group's strategy can "invade" a distrustful world – not engineered from the top-down, but evolved from the bottom-up...

(and then... >)

---

Maybe, just maybe...

We can all learn to live and let live.

[picture of Christmas Truce]

(<3 >)

---

CREATED BY NICKY CASE    
(full credits for code & sounds)

BASED OFF "THE EVOLUTION OF COOPERATION" (1984) BY ROBERT AXELROD    
(other footnotes)

this explorable explanation is open source & public domain: feel free to use it in your classroom, or remix the source code!

WANNA PLAY MORE INTERACTIVE EXPLANATIONS LIKE THIS ONE? TRY:

* Parable of the Polygons
* Neurotic Neurons
* Explorable Explanations

WANNA HELP ME MAKE MORE SHTUFF LIKE THIS? THROW COINS INTO THIS TRUST MACHINE: (patreon)

. . .

"The Evolution of Trust" (July 2017) was created with the trust & support of my many Patreon backers:

[scroll for patreon & playtesters]

---

// MORE HUMOR??? CONVERSATIONAL? "I"?

// MORE QUOTES???

// or... CUT DOWN CUT DOWN CUT DOOOOWWWWWWWN.
